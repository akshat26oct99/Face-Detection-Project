{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet_pytorch in e:\\anaconda\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\lib\\site-packages (from facenet_pytorch) (8.2.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\lib\\site-packages (from facenet_pytorch) (2.25.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from facenet_pytorch) (1.19.5)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda\\lib\\site-packages (from facenet_pytorch) (0.15.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests->facenet_pytorch) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests->facenet_pytorch) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\anaconda\\lib\\site-packages (from requests->facenet_pytorch) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: torch==2.0.0 in e:\\anaconda\\lib\\site-packages (from torchvision->facenet_pytorch) (2.0.0)\n",
      "Requirement already satisfied: sympy in e:\\anaconda\\lib\\site-packages (from torch==2.0.0->torchvision->facenet_pytorch) (1.8)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from torch==2.0.0->torchvision->facenet_pytorch) (3.0.12)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\lib\\site-packages (from torch==2.0.0->torchvision->facenet_pytorch) (2.5)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from torch==2.0.0->torchvision->facenet_pytorch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\lib\\site-packages (from torch==2.0.0->torchvision->facenet_pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in e:\\anaconda\\lib\\site-packages (from jinja2->torch==2.0.0->torchvision->facenet_pytorch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in e:\\anaconda\\lib\\site-packages (from networkx->torch==2.0.0->torchvision->facenet_pytorch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\anaconda\\lib\\site-packages (from sympy->torch==2.0.0->torchvision->facenet_pytorch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection and recognition inference pipeline\n",
    "\n",
    "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and recogition on an image dataset using an Inception Resnet V1 pretrained on the VGGFace2 dataset.\n",
    "\n",
    "The following Pytorch methods are included:\n",
    "* Datasets\n",
    "* Dataloaders\n",
    "* GPU/CPU processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, prewhiten\n",
    "import torch\n",
    "import tensorflow as TF\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "Default params shown for illustration, but not needed. Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "Set classify=True for pretrained classifier. For this example, we will use the model to output embeddings/CNN features. Note that for inference, it is important to set the model to `eval` mode.\n",
    "\n",
    "See `help(InceptionResnetV1)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a dataset and data loader\n",
    "\n",
    "We add the `idx_to_class` attribute to the dataset to enable easy recoding of label indices to identity names later one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder(r'C:\\Users\\as922\\OneDrive\\Desktop\\facenet-pytorch-master\\facenet-pytorch-master\\data\\New folder')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n",
    "\n",
    "Iterate through the DataLoader object and detect faces and associated detection probabilities for each. The `MTCNN` forward method returns images cropped to the detected face, if a face was detected. By default only a single detected face is returned - to have `MTCNN` return all detected faces, set `keep_all=True` when creating the MTCNN object above.\n",
    "\n",
    "To obtain bounding boxes rather than cropped face images, you can instead call the lower-level `mtcnn.detect()` function. See `help(mtcnn.detect)` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected with probability: 0.999983\n",
      "Face detected with probability: 0.999733\n",
      "Face detected with probability: 0.999934\n",
      "Face detected with probability: 0.999880\n",
      "Face detected with probability: 0.999992\n"
     ]
    }
   ],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate image embeddings\n",
    "\n",
    "MTCNN will return images of faces all the same size, enabling easy batch processing with the Resnet recognition module. Here, since we only have a few images, we build a single batch and perform inference on it. \n",
    "\n",
    "For real datasets, code should be modified to control batch sizes being passed to the Resnet, particularly if being processed on a GPU. For repeated testing, it is best to separate face detection (using MTCNN) from embedding or classification (using InceptionResnetV1), as calculation of cropped faces or bounding boxes can then be performed a single time and detected faces saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print distance matrix for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Female    Female      Male      Male      Male\n",
      "Female  0.000000  0.887728  1.447480  1.429847  1.399073\n",
      "Female  0.887728  0.000000  1.313749  1.388377  1.379655\n",
      "Male    1.447480  1.313749  0.000000  1.013447  1.038684\n",
      "Male    1.429847  1.388377  1.013447  0.000000  1.100503\n",
      "Male    1.399073  1.379655  1.038684  1.100503  0.000000\n"
     ]
    }
   ],
   "source": [
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "print(pd.DataFrame(dists, columns=names, index=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Match with angelina_jolie, Gender - Female\n"
     ]
    }
   ],
   "source": [
    "def recognize_celebrity(img_path):\n",
    "    # Load image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Detect face and align image\n",
    "    x_aligned, prob = mtcnn(img, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        # Get embeddings\n",
    "        embeddings = resnet(x_aligned.unsqueeze(0)).detach().cpu()\n",
    "\n",
    "        # Load dataset\n",
    "        dataset_path = r'C:\\Users\\as922\\OneDrive\\Desktop\\facenet-pytorch-master\\facenet-pytorch-master\\data\\New Folder' # inside this new folder we have 2 folder male and female\n",
    "        dataset = datasets.ImageFolder(dataset_path)\n",
    "\n",
    "        # Find closest match\n",
    "        min_dist = float('inf')\n",
    "        match_name = ''\n",
    "        match_path = ''\n",
    "        for folder_path, _, file_names in os.walk(dataset_path):\n",
    "            for file_name in file_names:\n",
    "                if file_name.endswith('.jpg') or file_name.endswith('.jpeg') or file_name.endswith('.png'):\n",
    "                    celeb_path = os.path.join(folder_path, file_name)\n",
    "                    celeb_img = Image.open(celeb_path)\n",
    "\n",
    "                    # Detect face and align image\n",
    "                    x_aligned, prob = mtcnn(celeb_img, return_prob=True)\n",
    "                    if x_aligned is not None:\n",
    "                        # Get embeddings and calculate distance\n",
    "                        celeb_embeddings = resnet(x_aligned.unsqueeze(0)).detach().cpu()\n",
    "                        dist = (embeddings - celeb_embeddings).norm().item()\n",
    "\n",
    "                        # Update closest match\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            match_name = os.path.basename(os.path.dirname(celeb_path))\n",
    "                            match_path = os.path.dirname(celeb_path)\n",
    "\n",
    "        gender = os.path.basename(os.path.dirname(match_path))       \n",
    "        \n",
    "        # Return result\n",
    "        if match_name:\n",
    "            return f\"Face Match with {match_name}, Gender - {gender}\"\n",
    "        else:\n",
    "            return \"No match found\"\n",
    "    else:\n",
    "        return \"No face detected in image\"\n",
    "\n",
    "\n",
    "# Test the function\n",
    "img_path = r'C:\\Users\\as922\\Downloads\\16804254165994.jpg'\n",
    "result = recognize_celebrity(img_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
